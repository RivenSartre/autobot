# README.md

## autobot
  这个文档是自动化工程学院迎新机器人项目的综述，这个GitHub仓库负责代码托管和事务交流。

  简单的说，这里是进行代码交流的，大家将每次自己写好的代码打包上传，其他组员可以下载。
**注意：每次的代码要打包在一个文件夹之中，并标好和版本号，文件夹名只用英文，比如0.1，1.2等。**
另外相关的开发同学一定要做好每个版本的工程本地文件，做好备份以防意外。

  这里简单梳理一下我们的工作内容：
****
## 1. 方案总述

  ​	“自动化电力萌娃（暂名）”项目，是开发自动化工程学院迎新机器人的科创项目。主要开发时间是从2021年5月1日至2021年8月22日，并在2021年9月的迎新之前完成整机的调试工作。方案要实现一个能够实现简单语音交流的迎新机器人，能够依托云端语音包，根据已定的对话模板，进行关于校园及学院问题的简单沟通；方案要实现简单的校园指路功能，能够提供校园主要场所的导引与介绍；方案要实现对新生人脸的识别工作，能够通过拍摄人脸识别出本院新生，并显示出其学号班级等基本信息。进一步的，方案要实现简单的手臂动作，可以根据既定程序实现手臂的简易动作，在进一步能执行可现场编程的动作交互。

  ​ 本方案由六名同学负责协调与各功能开发，刘辰宇负责团队的工作统筹，进度的调配，人脸识别功能的开发工作；张晓东负责机器人各部件组装与整体硬件系统的搭建与维护；周明东，张元曦，鲍亚君负责语音系统的开发，人机界面的搭建和各软件功能的集成；汪美谷负责人机界面的UI设计，校园地图的绘制和人机语音交流的问题设计。李涞源，韩立婷，康靖，沈思吉同学作为项目顾问，协助六名核心人员完成相关设计的构思和开发工作。

  ​	本方案的三名指导老师为张传林，夏飞，冒建亮，指导和协助开发同学完成本项目。

## 2. 重点功能

- 实现简单的人机语音交互
  - 通过在本地采集问题的语音，处理上传云端，并接收问题回答文件，在本地处理后并进行语音回答。
  - 设置好基本问题的回答答案，和简单的日常对话。
  - 设置好提问模板，以便新生进行交流。
  - 设置保底回答。
- 实现新生的人像识别
  - 导入新生的人像信息，训练程序能够识别每一个新生的人脸。
  - 通过本地程序实现人像的拍摄采集，人脸识别，并显示对应学生基本信息（如学号，班级，辅导员，宿舍号等）。
  - 可以搭建简易的签到系统。
- 实现校园的导航功能
  - 绘制简洁卡通的校园地图，表示出自动化新生常去的地点，能够通过语音交互或者点触的方式实现相关场所的寻路功能。
  - 重点标示出报到地点，图书馆，能机楼（自动化办公室所在地），教学楼，食堂，学生宿舍，大门的方位和。
- 实现较为美观的人机界面
  - 能将上述的基本功能整合在一个人机交互界面中，可以保持语音系统时刻待机和点触功能长开，可以通过两种方式实现个功能的启用。
  - 设计美观的人机界面，设计有学院风格的软件UI。

## 3. 难点攻关

1. 摸清该机器人的硬件构造
   - 主机及显示器部分，电源稳压部分，电机与驱动部分，摄像头部分，头部显示屏部分，声卡采集与音响部分，网卡部分，其他部分。
   - 能更换和增减部分模块。
   - 增加的模块能被主机程序驱动并实现功能集成在人机交互界面之中。
2. 语音交互系统的开发
   - 编程语言的选择
   - 语音交互服务器的选择
   - 音频的采集、处理、加密编码、服务器搭建、本地与服务器的通信协议
   - 语音交互系统的代码实现
3. 人机界面的开发与功能集成
   - 将所有已实现功能可以通过一个人机界面调用，并调试至稳定运行。
   - 人机界面编程语言的选择
   - 各硬件的驱动

## 4. 组员分工

- 刘辰宇：**项目协调**；人脸识别功能开发。
- 周明东：**软件开发**；人脸识别功能开发，语音交互系统开发。
- 鲍亚君：**软件开发**；手臂动作功能开发，语音调试。
- 张元曦：**软件开发**；语音交互系统开发。
- 汪美谷：**美工设计**；地图绘制，UI设计，外观涂鸦，手臂动作设计。
- 张晓东：**硬件开发**；手臂动作功能开发，硬件系统搭建。

## 5. 日程安排

- 5月：基础阶段
  - 第九周 *4.30~5.2*   各组员系统了解自己负责的功能的系统组成和实现案例，先看别人的实现方案，再具体看方案细节的实现方法。
  - 第十周 *5.3~5.9*   开例会讨论各自方案的实现步骤，完善日程安排。勘察迎新场地。
  - 第十一周 *5.10~5.16*   
  - 第十二周 *5.17~5.23*   弄清机器人已有的硬件系统，进行声卡网课的调试工作
  - 第十三周 *5.24~5.30*    校园地图的绘制
- 6月：设计阶段
  - 第十四周 *5.31~6.5*    人脸识别系统的软硬件实现，人机语音问答内容的设计
  - 第十五周 *6.7~6.13*    人机语音交互的程序实现
  - 第十六周 *6.14~6.20*     
  - 第十七周 *6.21~6.27*    
  - 第十八周 *6.28~7.4*    实现人机软件界面的功能设计和UI设计
- 7月：开发阶段
  - 第十九周 *7.5~7.11*   简单手臂动作的控制实现
  - 假期一周 *7.12~7.18*  
  - 假期二周 *7.19~7.25*    实现语音导航和点触导航功能
  - 假期三周 *7.26~8.1*    能从人机界面实现已有功能的调用和交互
- 8月：调试阶段
  - 假期四周 *8.2~8.8*   
  - 假期五周 *8.9~8.15*  
  - 假期六周 *8.16~8.22*   全部预期功能的基本实现
  - 假期七周 *8.23~8.29*   
- 9月：验收阶段
  - 开学前 *8.30~开学前*   调试机器人能够正常运行



## 6. 其他问题
- 本项目可以申请互联网+大学生科创竞赛。
- 手臂动作为附加项
- 如果有余力可以考虑其他功能
- 最后将所有工程文件整理打包上传仓库，以留给下一届团队继续维护发展


****

另外请大家在下几个文档中及时更新工作进度和遇到的问题。**如负责机器视觉的同学在2021年5月1日完成了面部特征提取的代码开发，但是发现有一些bug，则请当前工作结束时在VISUAL.md文件中写下当日的开发进度并记录bug**，记得在*Commit changes*中简要填写一下修改内容。
